{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc0f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c7a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./testImages/lionel_messi.jpg')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0207f1ab",
   "metadata": {},
   "source": [
    "Shape has 3 dimensions: x, y, rgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49ef1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52189778",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayImg = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "grayImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46cc9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71022ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grayImg, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d4c2b",
   "metadata": {},
   "source": [
    "## Face detection using Haar Cascades\n",
    "\n",
    "<a href='https://docs.opencv.org/3.4/d2/d99/tutorial_js_face_detection.html' > openCV documentation on object detection using Haar feature-based cascade classifiers </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df02973",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier('./opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv.CascadeClassifier('./opencv/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "faces = face_cascade.detectMultiScale(grayImg, 1.3, 5)\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc5c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "( x, y, w, h) = faces[0]\n",
    "x, y, w, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690eec1",
   "metadata": {},
   "source": [
    "### Detecting face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75c1f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_img = cv.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 4)\n",
    "plt.imshow(face_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf630e",
   "metadata": {},
   "source": [
    "### Plotting eyes next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0636717",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()\n",
    "for (x,y,w,h) in faces:\n",
    "    face_img = cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),4)\n",
    "    roi_gray = grayImg[y:y+h, x:x+w]\n",
    "    roi_color = face_img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),4)\n",
    "        \n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(face_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383a7d4",
   "metadata": {},
   "source": [
    "### Cropping the facial region of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b838782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(roi_color, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0144aa7",
   "metadata": {},
   "source": [
    "## Creating a function to carry out all the above steps on any image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "678b0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedImageIf2Eyes(image_path):\n",
    "    img = cv.imread(image_path)\n",
    "    grayImg = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(grayImg, 1.3, 5)    \n",
    "    for(x, y, w, h) in faces:\n",
    "            roi_gray = grayImg[y:y+h, x:x+w]\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)        \n",
    "            if len(eyes) >=2:\n",
    "                return roi_color "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a72d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "originalImg = cv.imread('./testImages/lionel_messi.jpg')\n",
    "plt.imshow(originalImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfafcd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "croppedImage = getCroppedImageIf2Eyes('./testImages/lionel_messi.jpg')\n",
    "plt.imshow(croppedImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87cd4cb",
   "metadata": {},
   "source": [
    "### Testing with image where eyes cannot be detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dc272a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "originalImg = cv.imread('./testImages/lionel_messi_3.jpg')\n",
    "plt.imshow(originalImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ddf2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "croppedImage2 = getCroppedImageIf2Eyes('./testImages/lionel_messi_3.jpg')\n",
    "croppedImage2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ea871",
   "metadata": {},
   "source": [
    "## Cropping every image from all folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad9d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./dataset/\"\n",
    "path_to_person_data = \"./dataset/cropped/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dd505af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_dirs = []\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        img_dirs.append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54eb96a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "457a60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists(path_to_person_data):\n",
    "    shutil.rmtree(path_to_person_data)\n",
    "os.mkdir(path_to_person_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "942e6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_dirs = []\n",
    "person_file_names_dict = {}\n",
    "\n",
    "\n",
    "for img_dir in img_dirs:\n",
    "    count = 1\n",
    "    person_name = img_dir.split('/')[-1]\n",
    "    person_file_names_dict[person_name] = []    \n",
    "    for entry in os.scandir(img_dir):\n",
    "        roi_color = getCroppedImageIf2Eyes(entry.path)\n",
    "        if roi_color is not None:\n",
    "            cropped_folder = path_to_person_data + person_name\n",
    "            if not os.path.exists(cropped_folder):\n",
    "                os.makedirs(cropped_folder)\n",
    "                cropped_image_dirs.append(cropped_folder)\n",
    "                print(\"Generating cropped images in folder: \", cropped_folder)\n",
    "            cropped_file_name = person_name + str(count) + \".png\"\n",
    "            cropped_file_path = cropped_folder + \"/\" + cropped_file_name           \n",
    "            cv.imwrite(cropped_file_path, roi_color)\n",
    "            person_file_names_dict[person_name].append(cropped_file_path)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a3299a",
   "metadata": {},
   "source": [
    "### Dictionary of image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90dbfd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_file_names_dict = {}\n",
    "for img_dir in cropped_image_dirs:\n",
    "    person_name = img_dir.split('/')[-1]\n",
    "    file_list = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        file_list.append(entry.path)\n",
    "    person_file_names_dict[person_name] = file_list\n",
    "person_file_names_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425fa1b",
   "metadata": {},
   "source": [
    "### Using wavelet transform as a feature for traning our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00ebb8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "def waveletTransform(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv.cvtColor( imArray,cv.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f729588",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_har = waveletTransform(croppedImage,'db1',5)\n",
    "plt.imshow(im_har, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5951cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {}\n",
    "count = 0\n",
    "for person_name in person_file_names_dict.keys():\n",
    "    class_dict[person_name] = count\n",
    "    count = count + 1\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "601bc668",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for person_name, training_files in person_file_names_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        scalled_raw_img = cv.resize(img, (32, 32))\n",
    "        img_har = waveletTransform(img,'db1',5)\n",
    "        scalled_img_har = cv.resize(img_har, (32, 32))\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(class_dict[person_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2b8dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X) #Each element in X is an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15ac841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[0]) #Size of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f0d3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e0cf61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X),4096).astype(float) #Converting to float\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77a19304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e62cc3",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f10880",
   "metadata": {},
   "source": [
    "### Using SVM to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb7094f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96d9bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84658b0",
   "metadata": {},
   "source": [
    "### Classification report on SVM\n",
    "<a href='https://en.wikipedia.org/wiki/F-score' > f1 score </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf18b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a438b",
   "metadata": {},
   "source": [
    "Using GridSearch to try out different models with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c63981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f15a7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43a10483",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df #df gives validation dataset results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a4301ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1729fa5",
   "metadata": {},
   "source": [
    "### These are the results for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eff00408",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators['svm'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37c854b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators['random_forest'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40936c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators['logistic_regression'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d14d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classf = best_estimators['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1a230b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, best_classf.predict(X_test))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c08321c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d7dda1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4848842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(best_classf, 'saved_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f0ebaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"class_dictionary.json\",\"w\") as f:\n",
    "    f.write(json.dumps(class_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
